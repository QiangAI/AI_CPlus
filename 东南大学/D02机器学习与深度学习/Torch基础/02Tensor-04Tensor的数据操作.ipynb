{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- take函数从Tensor取值，\n",
    "    - 按照Storage的索引取值\n",
    "```python\n",
    "    Tensor.take(indices) -> Tensor      # 成员函数\n",
    "    torch.take(indices) -> Tensor        # 全局函数 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 3., 4., 5., 6.])\n",
      "tensor([1., 3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "])\n",
    "index = torch.tensor([0,2,3,4,5])    \n",
    "print(t.take(index))\n",
    "print(torch.take(t, index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## put_与set_函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 输入与修改Tensor的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. set_函数\n",
    "    - 替代\n",
    "```python\n",
    "    set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
    "```\n",
    "- 参数\n",
    "    - source (Tensor or Storage): 设置的源\n",
    "    - storage_offset (int, optional): 源的偏移位置\n",
    "    - size (torch.Size, optional): 返回的尺寸，\n",
    "    - stride (tuple, optional):  期望的步长，缺省是C连续的步长。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.],\n",
      "        [5., 6.]]) tensor([[3., 4.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Storage([1, 2, 3, 4, 5, 6, 7, 8, 9, 0])\n",
    "\n",
    "t2 = torch.Tensor(2, 3)  # 原来的被替代\n",
    "t3 = t2.set_(source=t, storage_offset=2, size=(2, 2), stride=(2, 1))\n",
    "print(t2, t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. put_函数\n",
    "    - 修改\n",
    "\n",
    "```python\n",
    "    put_(indices, tensor, accumulate=False) -> Tensor\n",
    "```\n",
    "\n",
    "- 参数：\n",
    "    - indices (LongTensor): 1维索引, 不需要使用命名参数。\n",
    "    - tensor (Tensor): 替换的新值\n",
    "    - accumulate (bool): 是否累加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2., 77.],\n",
      "        [88.,  5.,  6.]])\n",
      "tensor([[ 1.,  2., 77.],\n",
      "        [88.,  5.,  6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t2 = torch.Tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "])\n",
    "\n",
    "index = torch.LongTensor([2, 3])  # 替代的位置  \n",
    "new_values = torch.Tensor([[77], [88]])    # 必须与index一样的元素数\n",
    "t3 = t2.put_(index, new_values)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2., 80.],\n",
      "        [92.,  5.,  6.]])\n",
      "tensor([[ 1.,  2., 80.],\n",
      "        [92.,  5.,  6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t2 = torch.Tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "])\n",
    "\n",
    "index = torch.LongTensor([2, 3])  # 替代的位置  \n",
    "new_values = torch.Tensor([[77], [88]])    # 必须与index一样的元素数\n",
    "t3 = t2.put_(index, new_values, accumulate=True)\n",
    "print(t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand与expand_as函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 扩大原来张量的维数。\n",
    "    - as以已有的Tensor维数为目标。\n",
    "    - expand的原来的张量智能维度长为1的才能扩展，扩展原理不增加原来的数据，而是把stride修改为0，反复指向同一个数据位置。\n",
    "\n",
    "```python\n",
    "    expand(*sizes) -> Tensor\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [4., 4., 4., 4., 4.]])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [4., 4., 4., 4., 4.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1],\n",
    "    [4],\n",
    "])\n",
    "print(t.shape)\n",
    "print(t.expand(2, 5))    # 2可以使用-1，表示不修改第一维的长度（长度不为1的都不能扩展）\n",
    "print(t.expand(-1, 5))    # 2可以使用-1，表示不修改第一维的长度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trunc函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- trunc函数是截断，是对原来数据集取整后放回。\n",
    "\n",
    "```python\n",
    "    Tensor.trunc_() -> Tensor\n",
    "    torch.trunc() -> Tensor\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6],\n",
    "    [4.7, 5.8, 6.2],\n",
    "])\n",
    "\n",
    "print(t.trunc())   # 取整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## permute函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 维度重新排列\n",
    "\n",
    "```python\n",
    "    permute(*dims) -> Tensor\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5000, 4.7000],\n",
      "        [2.4000, 5.8000],\n",
      "        [3.6000, 6.2000]])\n",
      "tensor([[1.5000, 4.7000],\n",
      "        [2.4000, 5.8000],\n",
      "        [3.6000, 6.2000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6],\n",
    "    [4.7, 5.8, 6.2],\n",
    "])\n",
    "\n",
    "print(t.permute(1, 0))   # 行列互换，2维就只能是0，1，三维一次类推， 可以使用负数按照反方向使用\n",
    "print(t.permute(-1, -2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flip函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- flip函数与permute函数形式类似\n",
    "    - 用来反转矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.2000, 5.8000, 4.7000],\n",
      "        [3.6000, 2.4000, 1.5000]])\n",
      "tensor([[6.2000, 5.8000, 4.7000],\n",
      "        [3.6000, 2.4000, 1.5000]])\n",
      "tensor([[4.7000, 5.8000, 6.2000],\n",
      "        [1.5000, 2.4000, 3.6000]])\n",
      "tensor([[3.6000, 2.4000, 1.5000],\n",
      "        [6.2000, 5.8000, 4.7000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6],\n",
    "    [4.7, 5.8, 6.2],\n",
    "])\n",
    "\n",
    "print(t.flip(1, 0))     \n",
    "print(t.flip(-1, -2)) \n",
    "print(t.flip(0))   # 按照行翻转\n",
    "print(t.flip(1))    # 按照列翻转"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unfold函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对原有Tensor按照指定参数展开\n",
    "\n",
    "```python\n",
    "    unfold(dimension, size, step) -> Tensor\n",
    "```\n",
    "\n",
    "- 参数：\n",
    "    - dimension (int): 在哪个维上展开\n",
    "    - size (int): 展开的大小\n",
    "    - step (int): 展开的步长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.5000, 2.4000],\n",
      "         [2.4000, 3.6000],\n",
      "         [3.6000, 4.7000]],\n",
      "\n",
      "        [[4.7000, 5.8000],\n",
      "         [5.8000, 6.2000],\n",
      "         [6.2000, 7.8000]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "print(t.unfold(1, 2, 1))    # 按照列(就是每行)展开[1.5, 2.4, 3.6] 展开大小为2, 步长为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.5000, 4.7000],\n",
      "         [2.4000, 5.8000],\n",
      "         [3.6000, 6.2000],\n",
      "         [4.7000, 7.8000]]])\n"
     ]
    }
   ],
   "source": [
    "print(t.unfold(0, 2, 2))    # 按照行（就是每列）展开[1.5, 2.4, 3.6] 展开大小为2, 步长为1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unbind函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 维数收缩，或者删除一维\n",
    "\n",
    "```python\n",
    "    Tensor.unbind(dim=0) -> seq\n",
    "    torch.unbind(dim=0) -> seq\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.5000, 4.7000],\n",
      "        [2.4000, 5.8000],\n",
      "        [3.6000, 6.2000],\n",
      "        [4.7000, 7.8000]]),)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [1.5000, 4.7000],\n",
    "            [2.4000, 5.8000],\n",
    "            [3.6000, 6.2000],\n",
    "            [4.7000, 7.8000]\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "print(t.unbind(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1.5000, 2.4000, 3.6000, 4.7000]), tensor([4.7000, 5.8000, 6.2000, 7.8000]))\n",
      "(tensor([1.5000, 4.7000]), tensor([2.4000, 5.8000]), tensor([3.6000, 6.2000]), tensor([4.7000, 7.8000]))\n"
     ]
    }
   ],
   "source": [
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "print(t.unbind(dim=0))\n",
    "print(t.unbind(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 排序\n",
    "\n",
    "```python\n",
    "    Tensor. sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
    "    torch. sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.sort(\n",
      "values=tensor([[4.7000, 5.8000, 6.2000, 7.8000],\n",
      "        [1.5000, 2.4000, 3.6000, 4.7000]]),\n",
      "indices=tensor([[1, 1, 1, 1],\n",
      "        [0, 0, 0, 0]]))\n",
      "torch.return_types.sort(\n",
      "values=tensor([[1.5000, 2.4000, 3.6000, 4.7000],\n",
      "        [4.7000, 5.8000, 6.2000, 7.8000]]),\n",
      "indices=tensor([[0, 1, 2, 3],\n",
      "        [0, 1, 2, 3]]))\n",
      "tensor([[1.5000, 2.4000, 3.6000, 4.7000],\n",
      "        [4.7000, 5.8000, 6.2000, 7.8000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "print(t.sort(dim=0, descending=True))\n",
    "print(t.sort(dim=1, descending=False))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据选取\n",
    "\n",
    "```python\n",
    "    select(dim, index) -> Tensor\n",
    "```\n",
    "\n",
    "- 参数：\n",
    "    -  dim (int): 维数\n",
    "    - index (int): 索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.4000, 5.8000])\n",
      "tensor([2.4000, 5.8000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "print(t.select(dim=1, index=1))   # 等价于 t[ :, 1], \n",
    "print(t[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.6841e-34,  1.4013e-45,  2.5684e-34,  1.4013e-45, -8.4239e+29],\n",
      "         [-6.7587e+10,  3.6841e-34,  1.4013e-45,  2.5684e-34,  1.4013e-45],\n",
      "         [-4.1976e+12, -3.8982e+26,  3.6841e-34,  1.4013e-45,  2.5684e-34],\n",
      "         [ 1.4013e-45,  1.7442e+28,  6.4513e+10,  3.6841e-34,  1.4013e-45]],\n",
      "\n",
      "        [[ 3.5379e-33,  1.4013e-45,  2.5913e-34,  1.4013e-45, -2.4605e-30],\n",
      "         [ 1.8904e-13,  3.5379e-33,  1.4013e-45,  2.5684e-34,  1.4013e-45],\n",
      "         [ 3.3660e+34,  1.9663e-25,  3.5379e-33,  1.4013e-45,  2.5684e-34],\n",
      "         [ 1.4013e-45, -1.2724e+13, -5.3310e-18,  3.5409e-33,  1.4013e-45]]])\n",
      "tensor([[[ 3.6841e-34,  1.4013e-45,  2.5684e-34,  1.4013e-45, -8.4239e+29],\n",
      "         [-6.7587e+10,  3.6841e-34,  1.4013e-45,  2.5684e-34,  1.4013e-45],\n",
      "         [-4.1976e+12, -3.8982e+26,  3.6841e-34,  1.4013e-45,  2.5684e-34],\n",
      "         [ 1.4013e-45,  1.7442e+28,  6.4513e+10,  3.6841e-34,  1.4013e-45]],\n",
      "\n",
      "        [[ 3.5379e-33,  1.4013e-45,  2.5913e-34,  1.4013e-45, -2.4605e-30],\n",
      "         [ 1.8904e-13,  3.5379e-33,  1.4013e-45,  2.5684e-34,  1.4013e-45],\n",
      "         [ 3.3660e+34,  1.9663e-25,  3.5379e-33,  1.4013e-45,  2.5684e-34],\n",
      "         [ 1.4013e-45, -1.2724e+13, -5.3310e-18,  3.5409e-33,  1.4013e-45]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor(2,3,4,5)\n",
    "print(t.select(dim=1, index=1))   # 等价于 t[ :, 1,  :,  :]\n",
    "print(t[ :, 1,  :,  :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 1],\n",
      "        [2, 0, 2]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "i = torch.tensor(\n",
    "    [[0, 1, 1],\n",
    "     [2, 0, 2]])\n",
    "v = torch.tensor([3, 4, 5], dtype=torch.float32)\n",
    "sp = torch.sparse_coo_tensor(i, v)  \n",
    "\n",
    "print(sp.coalesce().indices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index_select函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用索引选择\n",
    "    - 按照索引在指定维度查找，是select的增强版本\n",
    "\n",
    "```python\n",
    "    index_select(dim, index) -> Tensor\n",
    "```\n",
    "\n",
    "- 参数：\n",
    "    - dim选择的维数，\n",
    "    - index选择索引，index支持多个查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4000, 3.6000],\n",
      "        [5.8000, 6.2000]])\n",
      "tensor([[2.4000, 3.6000],\n",
      "        [5.8000, 6.2000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "print(t.index_select(1,  torch.tensor([1,2])))   # 选择列（dim=1表示列），选择1与2列，等价于t[:, [1,2]]\n",
    "print(t[:, [1,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index_put_与index_put函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 按照索引设置值。\n",
    "\n",
    "```python\n",
    "    index_put_(indices, value, accumulate=False) -> Tensor\n",
    "```\n",
    "\n",
    "- 参数：\n",
    "    - indices (tuple of LongTensor): 用来索引张量的元组，元组的元素是张量\n",
    "    - value (Tensor): 需要设置的值，必须与张量类型相同\n",
    "    - accumulate (bool): 累加（True）还是替代（False）？\n",
    "- 说明\n",
    "    - `tensor.index_put_(indices, value)` 与 `tensor[indices] = value`等价。\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5000, 0.0000, 0.0000, 0.0000],\n",
      "        [4.7000, 0.0000, 6.2000, 7.8000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "print(\n",
    "    t.index_put( \n",
    "        indices=(torch.tensor([0, 0, 0, 1]), torch.tensor([1, 2, 3, 1])),   # 前面表示与后面形成一个定位坐标\n",
    "        values = torch.Tensor([0,0,0,0]),    # 匹配上面的长度\n",
    "        accumulate=False\n",
    "    )\n",
    ")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index_fill与index_fill_函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 填充数据到张量\n",
    "\n",
    "```python\n",
    "    index_fill_(dim, index, val) -> Tensor\n",
    "```\n",
    "\n",
    "- 参数：\n",
    "    - dim (int): 索引所在维度\n",
    "    - index (LongTensor): 索引\n",
    "    - val (float): 需要填充的值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5000, 88.0000, 88.0000,  4.7000],\n",
      "        [ 4.7000, 88.0000, 88.0000,  7.8000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "print(t.index_fill(1, torch.LongTensor([1, 2]), 88))   # 按照列，填充1与2列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index_add与index_add_函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 与index_fill一样，差别就是运算不同，使用的是add累加操作\n",
    "\n",
    "```python\n",
    "    index_add_(dim, index, tensor) -> Tensor\n",
    "```\n",
    "\n",
    "- 参数：\n",
    "    - dim (int): 索引的维度\n",
    "    - index (LongTensor)：索引\n",
    "    - source：与index与dim指定的形状一样：文档中是tensor，实际上是source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.5000,  90.4000, 102.6000,   4.7000],\n",
      "        [  4.7000,  71.8000,  83.2000,   7.8000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "v = torch.Tensor([[88, 99], [66, 77]])\n",
    "print(\n",
    "    t.index_add(dim=1, index=torch.LongTensor([1, 2]), source=v)\n",
    ")   # 按照列加，对1与2列添加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## index_copy与index_copy_函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 实际是index_fill与index_put功能融合版本,使用方式类似于index_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5000, 88.0000, 99.0000,  4.7000],\n",
      "        [ 4.7000, 66.0000, 77.0000,  7.8000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "v = torch.Tensor([[88, 99], [66, 77]])\n",
    "print(\n",
    "    t.index_copy(dim=1, index=torch.LongTensor([1, 2]), source=v)\n",
    ")   # 按照列加，对1与2列添加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gather函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \n",
    "\n",
    "```python\n",
    "     gather(dim, index) -> Tensor\n",
    "```\n",
    "\n",
    "- 参数：\n",
    "    - dim：维度，应该是int\n",
    "    - index：索引，应该是Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4000, 2.4000, 2.4000],\n",
      "        [4.7000, 4.7000, 4.7000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "print(\n",
    "    t.gather(\n",
    "        dim=1, \n",
    "        index=torch.LongTensor(\n",
    "            [\n",
    "                [1, 1, 1],            # 表示取得第1列，取三次, 取值智能是行的所用   ：dim=1，就需要index.shape[0] = t.shape[0]\n",
    "                [0, 0, 0]           # 表述第二行的第0列。取三次\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")   # 按照列加，对1与2列添加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.7000, 5.8000, 3.6000, 4.7000],\n",
      "        [4.7000, 2.4000, 6.2000, 7.8000],\n",
      "        [4.7000, 5.8000, 3.6000, 4.7000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "print(\n",
    "    t.gather(\n",
    "        dim=0, \n",
    "        index=torch.LongTensor(\n",
    "            [\n",
    "                [1, 1, 0, 0],    # 这列的列对应原来的列，行可以随意，但行只能是0与1\n",
    "                [1, 0, 1, 1],\n",
    "                [1, 1, 0, 0] \n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")   # 按照列加，对1与2列添加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chunk函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  把张量按照指定的维度分多块。\n",
    "\n",
    "```python\n",
    "    chunk(chunks, dim=0) -> List of Tensors\n",
    "```\n",
    "\n",
    "- 参数\n",
    "    - chunks：指定块数\n",
    "    - dim：指定维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1.5000, 2.4000],\n",
      "        [4.7000, 5.8000]]), tensor([[3.6000, 4.7000],\n",
      "        [6.2000, 7.8000]]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "print(t.chunk(chunks=2, dim=1))  # 按照列分成2块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply_函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 遍历每个元素，对元素进行定制处理，这是numpy与pandas中的套路。\n",
    "    - 调用的是函数或者可调用对象。\n",
    "    - 可调用函数接受每个元素，返回值替代原来张量中的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5 <class 'float'>\n",
      "2.4000000953674316 <class 'float'>\n",
      "3.5999999046325684 <class 'float'>\n",
      "4.699999809265137 <class 'float'>\n",
      "4.699999809265137 <class 'float'>\n",
      "5.800000190734863 <class 'float'>\n",
      "6.199999809265137 <class 'float'>\n",
      "7.800000190734863 <class 'float'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[101.5000, 102.4000, 103.6000, 104.7000],\n",
       "        [104.7000, 105.8000, 106.2000, 107.8000]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "def deal_data(e):\n",
    "    print(e, type(e))\n",
    "    return e + 100\n",
    "\n",
    "\n",
    "t.apply_(deal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## where函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 查询函数，与numpy与pandas中的where一个套路。\n",
    "\n",
    "```python\n",
    "    where(condition, y) -> Tensor\n",
    "```\n",
    "\n",
    "- 参数：\n",
    "    -  condition (BoolTensor): 逻辑张量BoolTensor；\n",
    "    - y (Tensor): 备选张量值，如果条件为True，就返回被操作的张量，否则返回y指定的张量\n",
    "        - 类似其他语言中的三目运算；\n",
    "        - Python中就是解析表达式；\n",
    "- where函数操作定义：\n",
    "    - $ \\text{out}_i = \\begin{cases}\n",
    "                                \\text{input}_i & \\text{if } \\text{condition}_i \\\\\n",
    "                                \\text{y}_i & \\text{otherwise} \\\\\n",
    "                            \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上面的操作都是按位操作的，y的形状必须与被操作张量一致, 或者标量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.0000, 9.0000, 3.6000, 4.7000],\n",
      "        [4.7000, 5.8000, 6.2000, 7.8000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "y = torch.Tensor([\n",
    "    [8, 8, 8, 8],\n",
    "    [8, 8, 8, 8],\n",
    "])\n",
    "\n",
    "r = t.where(condition=(t>3), other=torch.Tensor([9]))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0, 0, 1, 1, 1, 1]), tensor([2, 3, 0, 1, 2, 3]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "r = torch.where(t>3)  # 返回条件为真的元素的下标\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scatter函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 修改数据，类似put_与index_put等函数，\n",
    "\n",
    "```python\n",
    "    scatter_(dim, index, src) -> Tensor\n",
    "```\n",
    "\n",
    "- 参数：\n",
    "    - dim (int): the axis along which to index：索引的维度。\n",
    "    - index (LongTensor): the indices of elements to scatter：索引\n",
    "    - src (Tensor): the source element(s) to scatter：需要写入的数据\n",
    "    - value (float): the source element(s) to scatter：与src选一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scatter函数还包含\n",
    "    - scatter_add函数，使用都一样，唯一差别是累加的功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5000, 8.0000, 8.0000, 4.7000],\n",
      "        [4.7000, 5.8000, 6.2000, 8.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "y = torch.Tensor([\n",
    "    [8, 8, 8, 8],\n",
    "    [8, 8, 8, 8],\n",
    "])\n",
    "print(\n",
    "    t.scatter_(\n",
    "        dim=1, \n",
    "        index=torch.LongTensor(    # shape必须与被操作Tensor一样\n",
    "            [\n",
    "                [1,2],      # 因为dim=1，这里的1，2，3就是列的索引\n",
    "                [3,3]\n",
    "            ]),\n",
    "        src=y\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5 8.  8.  4.7]\n",
      " [4.7 5.8 6.2 8. ]]\n"
     ]
    }
   ],
   "source": [
    "# 在numpy中等价的操作\n",
    "import numpy as np\n",
    "t = np.array([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "t[0, [1, 2]] =[8, 8]\n",
    "t[1, [3, 3]] = [8,8]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## masked_\\*\\*函数\n",
    "\n",
    "- 类似逻辑下标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.5000,   2.4000, 100.0000, 100.0000],\n",
      "        [100.0000, 100.0000, 100.0000, 100.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "t[t>3] =100\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这个系列函数包含3个函数：\n",
    "    - masked_fill_\n",
    "    - masked_scatter_\n",
    "    - masked_select\n",
    "    \n",
    "- masked就是遮罩的意思，在处理数据过程中只对masked的范围的数据处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. masked_select函数\n",
    "\n",
    "```python\n",
    "    masked_select(mask) -> Tensor\n",
    "        - mask (BoolTensor): 逻辑Tensor\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False,  True,  True],\n",
      "        [ True,  True,  True,  True]])\n",
      "tensor([3.6000, 4.7000, 4.7000, 5.8000, 6.2000, 7.8000])\n",
      "tensor([3.6000, 4.7000, 4.7000, 5.8000, 6.2000, 7.8000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "mask = t>3\n",
    "print(mask)\n",
    "print(t.masked_select(mask))\n",
    "print(t[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. masked_scatter_函数\n",
    "```python\n",
    "    masked_scatter_(mask, source)\n",
    "        - mask (BoolTensor): 逻辑Tensor\n",
    "        - source (Tensor): 替换值的张量\n",
    "```\n",
    "\n",
    "- 说明：\n",
    "    - source (Tensor)张量是flat即可。不是flat的也会转换为flat，然后替换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5000,  2.4000, 88.0000, 88.0000],\n",
      "        [88.0000, 88.0000, 99.0000, 99.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "source = torch.Tensor([\n",
    "    [88, 88, 88, 88],\n",
    "    [99, 99, 99, 99],\n",
    "])\n",
    "mask = t>3\n",
    "\n",
    "r = t.masked_scatter(mask=mask,  source=source)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.5000,   2.4000, 100.0000, 200.0000],\n",
      "        [300.0000, 400.0000, 500.0000, 600.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "mask = t>3\n",
    "\n",
    "r = t.masked_scatter(mask=mask,  source=torch.Tensor([100,200,300,400,500,600,700]))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. masked_fill_函数\n",
    "```python\n",
    "    masked_fill_(mask, value)\n",
    "        - mask (BoolTensor): 逻辑Tensor\n",
    "        - value (float): 需要填充的值\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5000,  2.4000, 66.0000, 66.0000],\n",
      "        [66.0000, 66.0000, 66.0000, 66.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.Tensor([\n",
    "    [1.5, 2.4, 3.6, 4.7],\n",
    "    [4.7, 5.8, 6.2, 7.8],\n",
    "])\n",
    "\n",
    "source = torch.Tensor([\n",
    "    [88, 88, 88, 88],\n",
    "    [99, 99, 99, 99],\n",
    "])\n",
    "mask = t>3\n",
    "\n",
    "r = t.masked_fill(mask=mask,  value=66)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
