{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# é€»è¾‘å›å½’æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- é€»è¾‘å›å½’ä¸çº¿æ€§å›å½’æ˜¯æœ‰åŒºåˆ«çš„ï¼Œåªè¦ç”¨æ¥è§£å†³åˆ†ç±»çš„é—®é¢˜ï¼Œé€»è¾‘å›å½’æŠŠä»äºŒåˆ†ç±»åŸºæœ¬æ¨¡å‹åˆ†æï¼Œé€šè¿‡æ¦‚ç‡çš„æ–¹å¼æ¥åŒºåˆ†ä¸¤ä¸ªç±»ï¼š\n",
    "    - å±äºAçš„æ¦‚ç‡ï¼Œå±äºBçš„æ¦‚ç‡ï¼Œå“ªä¸ªå¯èƒ½æ¦‚ç‡å¤§å°±å±äºå“ªä¸€ç±»ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å†³ç­–æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- é€»è¾‘å›å½’çš„å†³ç­–æ¨¡å‹ï¼Œä½¿ç”¨çš„è¿˜æ˜¯æ˜¯çº¿æ€§æ¨¡å‹ï¼š\n",
    "    - $y = xW +b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä¸ºäº†ä»å½¢å¼ä¸Šæ¥è¿‘æ¦‚ç‡ï¼Œé‡‡ç”¨äº†ä¸€ä¸ªæ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆé€»è¾‘åˆ†å¸ƒå¯†åº¦å‡½æ•°ï¼‰\n",
    "    - $sigmoid(x) = \\dfrac{1}{1 + e^{-x}}$\n",
    "- ä»è€Œå†³ç­–æ¨¡å‹ä¸ºï¼š\n",
    "    - $y = sigmoid(xW +b) = \\dfrac{1}{1 + e^{-(xW + b)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŸå¤±æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- é€»è¾‘å›å½’ä¸­ï¼ŒæŸå¤±å‡½æ•°æ˜¯ï¼š     \n",
    "    - $Loss =\\sum\\limits_{i \\in \\text{æ•°æ®é›†}}y_i\\ ln(h(x_i)) +(1-y_i)\\ln(1-h(x_i))$      \n",
    "        - ä¸Šè¿°å…¬å¼è¢«ç§°ä¸ºäº¤å‰ç†µï¼ˆCross   Entropyï¼‰    \n",
    "        - å…¶ä¸­$h(x_i)=sigmoid(x_iW + b)= \\dfrac{1}{1+e^{-(x_iW + b)}}$         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# é€»è¾‘å›å½’PyTorchå®ç°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- é‡‡ç”¨PyTorchå®ç°ï¼Œæˆ‘ä»¬è¿˜æ˜¯ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ–¹æ³•å®ç°ã€‚\n",
    "\n",
    "- é¦–å…ˆè®¤è¯†ä¸‹æŸå¤±å‡½æ•°çš„è¡¨ç¤ºã€‚\n",
    "    - æŸå¤±å‡½æ•°çš„è¡¨è¾¾ä¸å†³ç­–å‡½æ•°æœ‰å…³ã€‚\n",
    "- æ•°æ®é›†ï¼š\n",
    "    - é‡‡ç”¨é¸¢å°¾èŠ±æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å†³ç­–å‡½æ•°çš„è¡¨ç¤º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- çº¿æ€§å‡½æ•°åœ¨torchä¸­å·²ç»å®šä¹‰ï¼šlinearå‡½æ•°ï¼›\n",
    "- sigmoidå‡½æ•°åœ¨torchä¸­å·²ç»å®šä¹‰ï¼šsigmoidå‡½æ•°ï¼›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1]) torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import torch\n",
    "\n",
    "data, target = sklearn.datasets.load_iris(return_X_y=True)\n",
    "\n",
    "x = torch.Tensor(data[0:100])   # å–å‰é¢100ä¸ªæ•°æ®æ ·æœ¬ \n",
    "y = torch.Tensor(target[0:100]).view(100,1) # å½¢çŠ¶ä¸xçº¿æ€§è¿ç®—åçš„å½¢çŠ¶ä¸€æ ·\n",
    "\n",
    "w = torch.randn(1, 4)    # æ³¨æ„å½¢çŠ¶(linearä¼šè‡ªåŠ¨è½¬ç½®) \n",
    "b = torch.randn(1)        # wï¼Œbæ˜¯å¯è®­ç»ƒçš„ï¼Œå°±æ˜¯éœ€è¦æ±‚å¯¼æˆ–è€…æ¢¯åº¦\n",
    "\n",
    "y_ = torch.nn.functional.linear(input=x, weight=w, bias=b)\n",
    "print(y_.shape)\n",
    "sy_ = torch.sigmoid(y_)\n",
    "print(sy_.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŸå¤±å‡½æ•°çš„è¡¨ç¤º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- é€»è¾‘å›å½’ä½¿ç”¨çš„æŸå¤±å‡½æ•°æ˜¯äº¤å‰ç†µï¼Œåœ¨Torchä¸­ä¹Ÿå°è£…äº†ä¸€ä¸ªå‡½æ•°ï¼š\n",
    "    - å…¶ä»–æŸå¤±å‡½æ•°åé¢ä¸“é—¨ç”¨ä¸€èŠ‚ä½œä¸ºä¸»é¢˜ä»‹ç»ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binary_cross_entropyå‡½æ•°\n",
    "\n",
    "- å¯¹æ•°æŸå¤±å‡½æ•°ï¼Œæ²¡æœ‰åšé€»è¾‘åˆ†å¸ƒå‡½æ•°ï¼ˆsigmoidï¼‰è¿ç®—\n",
    "\n",
    "```python\n",
    "    torch.nn.functional.binary_cross_entropy(input, target, weight=None, size_average=None, reduce=None, reduction='mean')\n",
    "```\n",
    "\n",
    "- å‚æ•°è¯´æ˜ï¼š\n",
    "    - inputï¼šå°±æ˜¯è®¡ç®—å‡ºæ¥çš„y_\n",
    "    - targetï¼šå°±æ˜¯åŸæ¥æ•°æ®é›†ä¸­æ ‡ç­¾y\n",
    "    - reduction: æŸå¤±çš„è®¡ç®—æ–¹å¼ï¼š\n",
    "        - å‡å€¼\n",
    "        - æ±‚å’Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binary_cross_entropy_with_logitså‡½æ•°\n",
    "\n",
    "- è‡ªåŠ¨åšé€»è¾‘åˆ†å¸ƒå‡½æ•°ï¼ˆsigmoidå‡½æ•°ï¼‰è¿ç®—ã€‚\n",
    "\n",
    "```python\n",
    "    torch.nn.functional.binary_cross_entropy_with_logits(input, target, weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æŸå¤±å‡½æ•°çš„ä¾‹å­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3298)\n",
      "tensor(32.9785)\n",
      "tensor(0.3298)\n",
      "tensor(32.9785)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import torch\n",
    "\n",
    "data, target = sklearn.datasets.load_iris(return_X_y=True)\n",
    "\n",
    "x = torch.Tensor(data[0:100])   # å–å‰é¢100ä¸ªæ•°æ®æ ·æœ¬ \n",
    "y = torch.Tensor(target[0:100]).view(100, 1) # å½¢çŠ¶ä¸xçº¿æ€§è¿ç®—åçš„å½¢çŠ¶ä¸€æ ·\n",
    "\n",
    "w = torch.randn(1, 4)    # æ³¨æ„å½¢çŠ¶(linearä¼šè‡ªåŠ¨è½¬ç½®) \n",
    "b = torch.randn(1)        # wï¼Œbæ˜¯å¯è®­ç»ƒçš„ï¼Œå°±æ˜¯éœ€è¦æ±‚å¯¼æˆ–è€…æ¢¯åº¦\n",
    "\n",
    "y_ = torch.nn.functional.linear(input=x, weight=w, bias=b)\n",
    "sy_ = torch.sigmoid(y_)\n",
    "\n",
    "loss_mean = torch.nn.functional.binary_cross_entropy_with_logits(y_, y, reduction=\"mean\")    # å¤šä¸€ä¸ªè¿ç®—ï¼Œé™¤ä»¥æ ·æœ¬ä¸ªæ•°\n",
    "print(loss_mean)\n",
    "loss_sum = torch.nn.functional.binary_cross_entropy_with_logits(y_, y, reduction=\"sum\")\n",
    "print(loss_sum)\n",
    "\n",
    "# è‡ªå·±æ‰‹å·¥åšsigmoidè¿ç®—\n",
    "loss_mean = torch.nn.functional.binary_cross_entropy(sy_, y, reduction=\"mean\")    # å¤šä¸€ä¸ªè¿ç®—ï¼Œé™¤ä»¥æ ·æœ¬ä¸ªæ•°\n",
    "print(loss_mean)\n",
    "loss_sum = torch.nn.functional.binary_cross_entropy(sy_, y, reduction=\"sum\")\n",
    "print(loss_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é€»è¾‘å›å½’åˆ†ç±»å®ç°\n",
    "\n",
    "- ä¸‹é¢çš„å®ç°æ–¹æ³•ï¼Œæ²¡æœ‰ä½¿ç”¨éšæœºæ¢¯åº¦ï¼Œå®ç°çš„æ ¸å¿ƒå…³é”®æ˜¯ï¼š\n",
    "    1. è¿­ä»£æ¢¯åº¦è®¡ç®—\n",
    "    2. æ•°æ®é¢„æµ‹åˆ†ç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯¯å·®æŸå¤±å€¼ï¼š  8.051266ï¼Œ\tå‡†ç¡®ç‡ä¸ºï¼š   50.00%\n",
      "è¯¯å·®æŸå¤±å€¼ï¼š  0.370522ï¼Œ\tå‡†ç¡®ç‡ä¸ºï¼š   95.00%\n",
      "è¯¯å·®æŸå¤±å€¼ï¼š  0.295042ï¼Œ\tå‡†ç¡®ç‡ä¸ºï¼š   95.00%\n",
      "è¯¯å·®æŸå¤±å€¼ï¼š  0.252245ï¼Œ\tå‡†ç¡®ç‡ä¸ºï¼š   95.00%\n",
      "è¯¯å·®æŸå¤±å€¼ï¼š  0.224739ï¼Œ\tå‡†ç¡®ç‡ä¸ºï¼š   96.00%\n",
      "è¯¯å·®æŸå¤±å€¼ï¼š  0.205526ï¼Œ\tå‡†ç¡®ç‡ä¸ºï¼š   96.00%\n",
      "è¯¯å·®æŸå¤±å€¼ï¼š  0.191302ï¼Œ\tå‡†ç¡®ç‡ä¸ºï¼š   96.00%\n",
      "è¯¯å·®æŸå¤±å€¼ï¼š  0.180313ï¼Œ\tå‡†ç¡®ç‡ä¸ºï¼š   97.00%\n",
      "è¯¯å·®æŸå¤±å€¼ï¼š  0.171543ï¼Œ\tå‡†ç¡®ç‡ä¸ºï¼š   97.00%\n",
      "è¯¯å·®æŸå¤±å€¼ï¼š  0.164363ï¼Œ\tå‡†ç¡®ç‡ä¸ºï¼š   97.00%\n",
      "è®­ç»ƒå®Œæ¯•ï¼\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import torch\n",
    "\n",
    "data, target = sklearn.datasets.load_iris(return_X_y=True)\n",
    "\n",
    "x = torch.Tensor(data[50:150])   # å–å‰é¢100ä¸ªæ•°æ®æ ·æœ¬ ï¼ˆå‰é¢50ä¸åé¢çš„ä¸¤ä¸ª50æ˜¯å¯åˆ†çš„ï¼Œåé¢ä¸¤ä¸ª50çº¿æ€§å¯åˆ†æ€§å·®ç‚¹ï¼‰\n",
    "y = torch.Tensor(target[0:100]).float().view(100, 1) # å½¢çŠ¶ä¸xçº¿æ€§è¿ç®—åçš„å½¢çŠ¶ä¸€æ ·\n",
    "\n",
    "w = torch.randn(1, 4)    \n",
    "b = torch.randn(1)        \n",
    "\n",
    "w.requires_grad = True   # å¯è®­ç»ƒï¼ˆx,yæ˜¯ä¸éœ€è¦è®­ç»ƒçš„ï¼‰\n",
    "b.requires_grad = True\n",
    "\n",
    "epoch = 10000\n",
    "learn_rate = 0.01\n",
    "\n",
    "for n in range(epoch):\n",
    "    # forwardï¼šå†³ç­–æ¨¡å‹è¡¨ç¤º\n",
    "    y_ = torch.nn.functional.linear(input=x, weight=w, bias=b)   # è®¡ç®—çº¿æ€§è¾“å‡º\n",
    "    sy_ = torch.sigmoid(y_)    # è®¡ç®—é€»è¾‘åˆ†å¸ƒè¿ç®—ï¼ˆè¾“å‡ºçš„å€¼å¯ä»¥ä½œä¸ºæ¦‚ç‡ä½¿ç”¨ï¼‰\n",
    "    # lossï¼šæŸå¤±å‡½æ•°è¡¨ç¤º\n",
    "    loss_mean = torch.nn.functional.binary_cross_entropy(sy_, y, reduction=\"mean\")\n",
    "    # backwardï¼šè®¡ç®—æ¢¯åº¦\n",
    "    loss_mean.backward()\n",
    "    \n",
    "    # æ›´æ–°æ¢¯åº¦\n",
    "    with torch.autograd.no_grad():   # å…³é—­æ¢¯åº¦è®¡ç®—è·Ÿè¸ª\n",
    "        w -= learn_rate * w.grad     # æ›´æ–°æƒé‡æ¢¯åº¦\n",
    "        w.grad.zero_()     # æ¸…ç©ºæœ¬æ¬¡è®¡ç®—çš„æ¢¯åº¦ï¼ˆå› ä¸ºæ¢¯åº¦æ˜¯ç´¯åŠ è®¡ç®—ï¼Œä¸æ¸…ç©ºå°±ç´¯åŠ ï¼‰\n",
    "        b -= learn_rate * b.grad     # æ›´æ–°åç½®é¡¹æ¢¯åº¦\n",
    "        b.grad.zero_()   \n",
    "        # è§‚å¯Ÿè®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±ä¸‹é™ï¼Œä¸è®­ç»ƒé›†é¢„æµ‹çš„å‡†ç¡®æ€§\n",
    "        if n % 1000 == 0:\n",
    "            print(F\"è¯¯å·®æŸå¤±å€¼ï¼š{loss_mean:10.6f}ï¼Œ\", end=\"\")\n",
    "            sy_[sy_ > 0.5] = 1\n",
    "            sy_[sy_ <= 0.5] = 0\n",
    "\n",
    "            correct_rate = (sy_ ==  y).float().mean()     # é€»è¾‘å€¼åœ¨Torchä¸ç»™è®¡ç®—å¹³å‡å€¼ï¼Œæ‰€ä»¥éœ€è¦è½¬æ¢ä¸ºfloatç±»å‹\n",
    "            print(F\"\\tå‡†ç¡®ç‡ä¸ºï¼š{correct_rate*100: 8.2f}%\")\n",
    "    \n",
    "print(\"è®­ç»ƒå®Œæ¯•ï¼\")   # ä¸‹é¢è¾“å‡ºçš„ç»“æœä¸sklearnä¸tensorflowè®­ç»ƒçš„ç»“æœä¸€è‡´"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æŸå¤±å‡½æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torchæä¾›çš„æŸå¤±å‡½æ•°æœ‰ï¼š\n",
    "    1. binary_cross_entropy\n",
    "    2. binary_cross_entropy_with_logits\n",
    "    3. poisson_nll_loss\n",
    "    4. cosine_embedding_loss\n",
    "    5. cross_entropy\n",
    "    6. ctc_loss\n",
    "    7. hinge_embedding_loss\n",
    "    8. kl_div\n",
    "    9. l1_loss\n",
    "    10. mse_loss\n",
    "    11. margin_ranking_loss\n",
    "    12. multilabel_margin_loss\n",
    "    13. multilabel_soft_margin_loss\n",
    "    14. multi_margin_loss\n",
    "    15. nll_loss\n",
    "    16. smooth_l1_loss\n",
    "    17. soft_margin_loss\n",
    "    18. triplet_margin_loss\n",
    "\n",
    "- è¿™äº›å‡½æ•°éƒ½æœ‰æ ‡å‡†çš„æ•°å­¦å…¬å¼ï¼Œæ¯ä¸ªå‡½æ•°çš„ä½¿ç”¨æ–¹å¼éƒ½ä¸€æ ·ï¼Œä¸‹é¢ç›´æ¥åˆ—å‡ºå…¬å¼ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## binary_cross_entropyä¸binary_cross_entropy_with_logitså‡½æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- è¿™ä¸¤ä¸ªå‡½æ•°çš„æœ¬è´¨æ˜¯ä¸€æ ·çš„ï¼ŒåŒºåˆ«åœ¨äºå¸¦åç¼€çš„with_logitså‡½æ•°å¯¹inputæ•°æ®å¤šä¸€ä¸ªsigmoidæ“ä½œã€‚\n",
    "    - sigmoidå‡½æ•°ä¹Ÿç§°logitså‡½æ•°ã€‚\n",
    "    - ä¸»è¦ç”¨äºäºŒåˆ†ç±»ï¼Œæ¯”å¦‚å…¸å‹çš„é€»è¾‘å›å½’ï¼Œä¾‹å­è§ä¸Šé¢ï¼›"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## poisson_nll_losså‡½æ•°\n",
    "\n",
    "- æ³Šæ¾è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±ï¼ˆPoisson negative log likelihood lossï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æ³Šæ¾åˆ†å¸ƒçš„å‡½æ•°ä¸ºï¼š\n",
    "    - $P(x=k)= \\dfrac{\\lambda ^ {k}}{k!} e ^{- \\lambda}$\n",
    "        - $\\lambda$è¡¨ç¤ºå•ä½æ—¶é—´å†…éšæœºäº‹ä»¶å‘ç”Ÿçš„æ¬¡æ•°ï¼›\n",
    "        - æ³Šæ¾åˆ†å¸ƒçš„æœŸæœ›ä¸æ–¹å·®éƒ½ä¸º$\\lambda$ï¼›\n",
    "        - $k!$æ˜¯$k$çš„é˜¶ä¹˜ï¼›"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æ³Šæ¾åˆ†å¸ƒä¸äºŒé¡¹åˆ†å¸ƒçš„å…³ç³»ï¼š\n",
    "    - æ³Šæ¾åˆ†å¸ƒæ˜¯ç”±äºŒé¡¹åˆ†å¸ƒæ¨å¯¼è€Œæ¥ï¼Œå½“äºŒé¡¹åˆ†å¸ƒçš„nå¾ˆå¤§ï¼Œpå¾ˆå°çš„æ—¶å€™ï¼Œæ³Šæ¾åˆ†å¸ƒå¯ä»¥ä½œä¸ºäºŒé¡¹åˆ†å¸ƒçš„è¿‘ä¼¼ï¼Œè¿™æ—¶$\\lambda=np$ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å‡½æ•°å®šä¹‰ï¼š\n",
    "\n",
    "```python\n",
    "    torch.nn.functional.poisson_nll_loss(input, target, log_input=True, full=False, size_average=None, eps=1e-08, reduce=None, reduction='mean')\n",
    "```\n",
    "\n",
    "- å‚æ•°ï¼š\n",
    "    - log_inputï¼šé€»è¾‘å€¼ï¼Œç”¨æ¥è®¾ç½®æ˜¯å¦å¯¹è¾“å…¥åšexpæŒ‡æ•°è¿ç®—ï¼š\n",
    "        - Falseï¼š$exp^{input} - target * input$\n",
    "        - Trueï¼š$input - target * log(input + eps)$ ï¼šå…¶ä¸­epsæ˜¯æ— ç©·å°é‡ï¼Œç”¨æ¥é˜²æ­¢inputä¸º0çš„æƒ…å†µã€‚\n",
    "    - fullï¼šæ˜¯å¦æ·»åŠ Stirlingè¿‘ä¼¼é¡¹\n",
    "        - $target * log(target) - target + 0.5 * log(2 * \\pi * target)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- æŸå¤±å‡½æ•°è®¡ç®—å…¬å¼ï¼š\n",
    "    - targetæ•°æ®æœä»æ³Šæ¾åˆ†å¸ƒï¼›\n",
    "    - $loss = \\sum \\limits _{i} ( e^{\\bar{y_i}} - y_i * \\bar{y_i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä¾‹å­ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0067)\n",
      "tensor(1.0067)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import torch\n",
    "\n",
    "data, target = sklearn.datasets.load_iris(return_X_y=True)\n",
    "\n",
    "x = torch.Tensor(data[0:100])   # å–å‰é¢100ä¸ªæ•°æ®æ ·æœ¬ \n",
    "y = torch.Tensor(target[0:100]).view(100, 1) # å½¢çŠ¶ä¸xçº¿æ€§è¿ç®—åçš„å½¢çŠ¶ä¸€æ ·\n",
    "\n",
    "w = torch.randn(1, 4)    # æ³¨æ„å½¢çŠ¶(linearä¼šè‡ªåŠ¨è½¬ç½®) \n",
    "b = torch.randn(1)        # wï¼Œbæ˜¯å¯è®­ç»ƒçš„ï¼Œå°±æ˜¯éœ€è¦æ±‚å¯¼æˆ–è€…æ¢¯åº¦\n",
    "\n",
    "y_ = torch.nn.functional.linear(input=x, weight=w, bias=b)\n",
    "sy_ = torch.sigmoid(y_)\n",
    "\n",
    "loss = torch.nn.functional.poisson_nll_loss(sy_, y)   # é»˜è®¤å‡å€¼ï¼šæ¯”è¾ƒå¸¸é‡‡ç”¨\n",
    "print(loss)\n",
    "\n",
    "# æ‰‹å·¥è®¡ç®—çš„æ•ˆæœï¼ˆlog_input = Trueï¼‰\n",
    "loss_manual = sy_.exp() - y * sy_\n",
    "loss_manual = loss_manual.mean()\n",
    "print(loss_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine_embedding_losså‡½æ•°\n",
    "\n",
    "- ç”¨æ¥åº¦é‡ä¸¤ä¸ªå‘é‡æ˜¯å¦ç›¸ä¼¼ã€‚ä¸»è¦ç”¨äºåŠç›‘ç£å­¦ä¹ ä¸å­¦ä¹ éçº¿æ€§åµŒå…¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å‡½æ•°å®šä¹‰ï¼š\n",
    "\n",
    "```python\n",
    "    torch.nn.functional.cosine_embedding_loss(\n",
    "        input1,     # å‘é‡1\n",
    "        input2,     # å‘é‡2\n",
    "        target,     # æ ‡ç­¾\n",
    "        margin=0, size_average=None, reduce=None, reduction='mean') â†’ Tensor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- è®¡ç®—å…¬å¼ï¼š\n",
    "    - $loss(x,y) = \\begin{cases} 1-cos(x_1, x_2)& å¦‚ y =1\\\\ max(0, cos(x_1, x_2)-margin )&å¦‚y=-1 \\\\   \\end{cases}$\n",
    "        - å…¶ä¸­ï¼š$cos(x_1, x_2)$æ˜¯å‘é‡$x_1,x_2$å¤¹è§’çš„ä½™å¼¦ã€‚\n",
    "        - marginçš„å–å€¼èŒƒå›´`[-1, 1]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nll_lossä¸cross_entropyå‡½æ•°\n",
    "\n",
    "- è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±å‡½æ•°ã€‚ç”¨æ¥åšCä¸ªç±»åˆ«çš„åˆ†ç±»æŸå¤±å‡½æ•°ã€‚\n",
    "- å®é™…ä¸Šè¿™ä¸¤ä¸ªå‡½æ•°æœ¬è´¨æ˜¯ä¸€æ ·çš„ã€‚\n",
    "    - cross_entropyå¤šåšäº†log_softmaxè¿ç®—"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å‡½æ•°å®šä¹‰ï¼š\n",
    "\n",
    "```python\n",
    "    torch.nn.functional.nll_loss(input, target, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
    "```\n",
    "\n",
    "- å‚æ•°è¯´æ˜ï¼š\n",
    "    - weightæ˜¯ä¸€ä¸ª1-Dçš„å¼ é‡ï¼ˆTensorï¼‰ï¼Œå¼ é‡çš„é•¿åº¦ä¸ç±»åˆ«æ•°ç›¸åŒï¼Œç”¨æ¥åŠ æƒæ¯ä¸ªåˆ†ç±»çš„ç±»åˆ«ã€‚\n",
    "    - inputï¼šæ˜¯2-Dæ•°æ®ï¼ˆNï¼ŒCï¼‰ï¼šNè¡¨ç¤ºæ•°é‡ï¼ŒCè¡¨ç¤ºåˆ†ç±»ç±»åˆ«ï¼›\n",
    "    - targetï¼šæ˜¯1-Dæ•°æ®ï¼Œé•¿åº¦ä¸ºNå³å¯ã€‚\n",
    "    \n",
    "- æç¤ºï¼š\n",
    "    - å› ä¸ºæ˜¯å¤šåˆ†ç±»é—®é¢˜ï¼Œæ‰€ä»¥å¯¹äºè¾“å‡ºçš„ç»“æœåº”è¯¥æ˜¯one-hotï¼Œæ¯”å¦‚2çš„one-hotå°±æ˜¯`[0,0,1,0,0,0]`ï¼Œå‡è®¾æœ€å¤§æ ‡ç­¾æ˜¯5ã€‚\n",
    "    - æ‰€ä»¥targetå¿…é¡»æ˜¯LongTensorç±»å‹çš„å¼ é‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä¾‹å­ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-9.1227)\n",
      "tensor(7.1684)\n",
      "tensor(7.1684)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import torch\n",
    "\n",
    "data, target = sklearn.datasets.load_iris(return_X_y=True)\n",
    "\n",
    "x = torch.Tensor(data)   #  ï¼ˆ150ï¼Œ4ï¼‰\n",
    "y = torch.Tensor(target).long()   # ï¼ˆ150ï¼‰\n",
    "\n",
    "w = torch.randn(3, 4)    # æ³¨æ„å½¢çŠ¶(linearä¼šè‡ªåŠ¨è½¬ç½®) ï¼š3è¡¨ç¤ºç±»åˆ«æ•°æ®ï¼ˆè¾“å‡ºçš„é•¿åº¦ï¼‰\n",
    "b = torch.randn(3)        # wï¼Œbæ˜¯å¯è®­ç»ƒçš„ï¼Œå°±æ˜¯éœ€è¦æ±‚å¯¼æˆ–è€…æ¢¯åº¦\n",
    "\n",
    "y_ = torch.nn.functional.linear(input=x, weight=w, bias=b)\n",
    "sy_ = y_.log_softmax(dim=1)\n",
    "# print(sy_.shape)\n",
    "\n",
    "loss = torch.nn.functional.nll_loss(y_, y)   # é»˜è®¤å‡å€¼ï¼šæ¯”è¾ƒå¸¸é‡‡ç”¨\n",
    "print(loss)\n",
    "loss = torch.nn.functional.nll_loss(sy_, y)   #\n",
    "print(loss)\n",
    "\n",
    "# cross_entropyäº¤å‰ç†µå‡½æ•°(å¤šè¿ç®—äº†ä¸€ä¸ªsigmoidè¿ç®—)\n",
    "loss_mamual = torch.nn.functional.cross_entropy(y_, y)     # nll_losså°±æ˜¯cross_entropç¼–ç ï¼Œè‡ªåŠ¨é‡‡ç”¨softmaxçš„one-hotb\n",
    "print(loss_mamual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_entropyçš„è¡¥å……"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cross_entropyå‡½æ•°çš„è®¡ç®—å…¬å¼æ˜¯ï¼š\n",
    "    - $loss(x, target) = -log(  \\dfrac{e ^ {x[target]} }{ \\sum \\limits _i e ^ {x[i]}}  ) = -x[target] + log(\\sum  \\limits _i e ^{x[i]})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä¸‹é¢å°±æ˜¯cross_entropyçš„æ‰‹å·¥å®ç°å‡½æ•°ï¼š\n",
    "     - åªä½¿ç”¨äº†ä¸€ä¸ªæ ·æœ¬æµ‹è¯•ï¼Œç±»åˆ«æ˜¯5ä¸ªç±»åˆ«ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¾“å…¥çš„æ•°æ®é›†ï¼š tensor([[1., 2., 3., 4., 5.]])\n",
      "è¾“å‡ºçš„æ•°æ®é›†ï¼š tensor([2])\n",
      "cross_entropyå‡½æ•°è¾“å‡ºçš„ç»“æœï¼š tensor(2.4519)\n",
      "æ‰‹å·¥è®¡ç®—ç»“æœï¼š tensor(2.4519)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "data_input = torch.FloatTensor([[1.0, 2.0, 3.0, 4.0, 5.0]])  # è®¡ç®—çš„y,\n",
    "\n",
    "data_target = torch.LongTensor([2])  # æ”¹ä¸‹æ ‡ä¸èƒ½è¶…è¿‡ä¸Šé¢çš„ç»´æ•°-1ï¼Œè¿™æ˜¯æŸå¤±å‡½æ•°çš„è®¡ç®—è¿‡ç¨‹å†³å®šçš„\n",
    "\n",
    "loss_out = torch.nn.functional.cross_entropy(data_input,  data_target)\n",
    "print(\"è¾“å…¥çš„æ•°æ®é›†ï¼š\", data_input)\n",
    "print(\"è¾“å‡ºçš„æ•°æ®é›†ï¼š\", data_target)\n",
    "print(\"cross_entropyå‡½æ•°è¾“å‡ºçš„ç»“æœï¼š\", loss_out)\n",
    "\n",
    "# ä¸‹é¢æ˜¯äº¤å‰ç†µå‡½æ•°çš„æ‰‹å·¥è®¡ç®—è¿‡ç¨‹\n",
    "\n",
    "result_1 = 0.0\n",
    "\n",
    "# è®¡ç®—ç¬¬ä¸€éƒ¨åˆ†ï¼šâˆ’ğ‘¥[ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡]\n",
    "for row in range(data_input.size()[0]):    # è¡Œå¾ªç¯(è¡¨ç¤ºæ ·æœ¬ä¸å¯¹åº”çš„æ ‡ç­¾),è¿™é‡Œå…¶å®æ˜¯1\n",
    "    result_1 -= data_input[row][data_target[row]]\n",
    "\n",
    "result_2 = 0.0\n",
    "\n",
    "# è®¡ç®—ç¬¬äºŒéƒ¨åˆ†ï¼šâˆ‘ğ‘’ğ‘¥[ğ‘–]\n",
    "for row in range(data_input.size()[0]):    # è¡Œå¾ªç¯(è¡¨ç¤ºæ ·æœ¬ä¸å¯¹åº”çš„æ ‡ç­¾),è¿™é‡Œå…¶å®æ˜¯1\n",
    "    for col in range(data_input.size()[1]):\n",
    "        result_2 += math.exp(data_input[row][col])\n",
    "\n",
    "# æœ€ç»ˆçš„ç»“æœ\n",
    "print(\"æ‰‹å·¥è®¡ç®—ç»“æœï¼š\", result_1 + math.log(result_2))   #\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nll_losså‡½æ•°çš„è¡¥å……\n",
    "\n",
    "- nll_losså‡½æ•°åå­—å«è´Ÿå¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼Œå®é™…ä¸Šæ ¹æœ¬æ²¡æœ‰åšä»»ä½•å¯¹æ•°è¿ç®—ï¼Œå…¶è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š\n",
    "     - $loss(x, target) = x[target]$\n",
    "     \n",
    "     - ç›´æ¥æŠŠxå½“æˆå¯¹æ•°æ¦‚ç‡ï¼Œå¹¶æœ€ç»ˆå–`x[target]`ä½œä¸ºè¿™ä¸ªç±»åˆ«çš„æŸå¤±ï¼Œæœ€åçš„æŸå¤±å°±æ˜¯æ‰€æœ‰æ ·æœ¬çš„æŸå¤±ã€‚\n",
    "     \n",
    "- æ³¨æ„ï¼š\n",
    "    - ä¸€èˆ¬nll_lossä¼šä¸log_softmaxä¸€èµ·ä½¿ç”¨ï¼Œæœ¬è´¨ä¹Ÿå°±ç­‰äºcross_entropyæŸå¤±å‡½æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0533)\n",
      "tensor(0.0533)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import torch\n",
    "\n",
    "data, target = sklearn.datasets.load_iris(return_X_y=True)\n",
    "\n",
    "x = torch.Tensor(data)   #  ï¼ˆ150ï¼Œ4ï¼‰\n",
    "y = torch.Tensor(target).long()   # ï¼ˆ150ï¼‰\n",
    "\n",
    "w = torch.randn(3, 4)    # æ³¨æ„å½¢çŠ¶(linearä¼šè‡ªåŠ¨è½¬ç½®) ï¼š3è¡¨ç¤ºç±»åˆ«æ•°æ®ï¼ˆè¾“å‡ºçš„é•¿åº¦ï¼‰\n",
    "b = torch.randn(3)        # wï¼Œbæ˜¯å¯è®­ç»ƒçš„ï¼Œå°±æ˜¯éœ€è¦æ±‚å¯¼æˆ–è€…æ¢¯åº¦\n",
    "\n",
    "y_ = torch.nn.functional.linear(input=x, weight=w, bias=b)\n",
    "# sy _ = y_.log_softmax(dim=1)\n",
    "sy_ = y_ \n",
    "loss = torch.nn.functional.nll_loss(sy_, y)   \n",
    "print(loss)\n",
    "\n",
    "# æ‰‹å·¥è®¡ç®—\n",
    "y_one = torch.nn.functional.one_hot(y).float()    # åšäº†ä¸ªå•çƒ­ç¼–ç ï¼Œæ–¹ä¾¿çŸ©é˜µè¿ç®—ï¼Œå¦åˆ™å°±è¦å–ä¸‹æ ‡ã€‚\n",
    "re = sy_ *  y_one\n",
    "# re = re.log()\n",
    "re = -re\n",
    "re =re.sum(dim=1)\n",
    "print(re.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mse_lossæŸå¤±å‡½æ•°\n",
    "\n",
    "- æœ€ç›´è§‚çš„æŸå¤±å‡½æ•°ï¼šå‡æ–¹å·®æŸå¤±ï¼Œè®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š\n",
    "    - $loss(x, target) = \\dfrac{1}{N} \\sum  \\limits _{i \\in N} (x_i - target_i) ^ 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å‡½æ•°è¯´æ˜ï¼š\n",
    "\n",
    "```python\n",
    "    torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='mean') â†’ Tensor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä¾‹å­ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.2841)\n",
      "tensor(14.2841)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import torch\n",
    "\n",
    "data, target = sklearn.datasets.load_iris(return_X_y=True)\n",
    "\n",
    "x = torch.Tensor(data)   #  ï¼ˆ150ï¼Œ4ï¼‰\n",
    "y = torch.Tensor(target).view(150,1)   # ï¼ˆ150ï¼‰\n",
    "\n",
    "w = torch.randn(1, 4)    # æ³¨æ„å½¢çŠ¶(linearä¼šè‡ªåŠ¨è½¬ç½®) ï¼š3è¡¨ç¤ºç±»åˆ«æ•°æ®ï¼ˆè¾“å‡ºçš„é•¿åº¦ï¼‰\n",
    "b = torch.randn(1)        # wï¼Œbæ˜¯å¯è®­ç»ƒçš„ï¼Œå°±æ˜¯éœ€è¦æ±‚å¯¼æˆ–è€…æ¢¯åº¦\n",
    "\n",
    "y_ = torch.nn.functional.linear(input=x, weight=w, bias=b)\n",
    "\n",
    "loss = torch.nn.functional.mse_loss(y_, y)   \n",
    "print(loss)\n",
    "\n",
    "# æ‰‹å·¥è®¡ç®—\n",
    "loss_manual = ((y -y_) ** 2).mean()\n",
    "print(loss_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l1_losså‡½æ•°\n",
    "\n",
    "- è¿™ä¸ªå‡½æ•°ä»å­—é¢ä¸Šç†è§£ï¼Œåº”è¯¥æ˜¯L1èŒƒæ•°åº¦é‡çš„è·ç¦»è¯¯å·®ï¼Œä¸å‡æ–¹å·®æŸå¤±å‡½æ•°å±äºåŒä¸€æ€§è´¨çš„æŸå¤±å‡½æ•°ã€‚å‡½æ•°å…¬å¼ä¸ºï¼š\n",
    "    - $loss(x, target) = \\dfrac{1}{N} \\sum \\limits _{i \\in N} | x_i - target_i |$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å‡½æ•°çš„å®šä¹‰\n",
    "\n",
    "```python\n",
    "    torch.nn.functional.l1_loss(input, target, size_average=None, reduce=None, reduction='mean') â†’ Tensor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä½¿ç”¨ä¾‹å­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6954)\n",
      "tensor(0.6954)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import torch\n",
    "\n",
    "data, target = sklearn.datasets.load_iris(return_X_y=True)\n",
    "\n",
    "x = torch.Tensor(data)   #  ï¼ˆ150ï¼Œ4ï¼‰\n",
    "y = torch.Tensor(target).view(150, 1) # ï¼ˆ150, 1ï¼‰\n",
    "\n",
    "w = torch.randn(1, 4)    # æ³¨æ„å½¢çŠ¶(linearä¼šè‡ªåŠ¨è½¬ç½®) ï¼š3è¡¨ç¤ºç±»åˆ«æ•°æ®ï¼ˆè¾“å‡ºçš„é•¿åº¦ï¼‰\n",
    "b = torch.randn(1)        # wï¼Œbæ˜¯å¯è®­ç»ƒçš„ï¼Œå°±æ˜¯éœ€è¦æ±‚å¯¼æˆ–è€…æ¢¯åº¦\n",
    "\n",
    "y_ = torch.nn.functional.linear(input=x, weight=w, bias=b)  \n",
    "sy_ = y_.sigmoid()    \n",
    "# sy_ = y_\n",
    "\n",
    "loss = torch.nn.functional.l1_loss(sy_, y)   # \n",
    "print(loss)\n",
    "\n",
    "# æ‰‹å·¥è®¡ç®—\n",
    "loss_manual = (y - sy_).abs().mean()\n",
    "print(loss_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kl_divå‡½æ•°\n",
    "\n",
    "- The `Kullback-Leibler divergence`_ Loss.\n",
    "    - ä¹Ÿç§°KLè·ç¦»ï¼Œä¸€ç§ä¸åŒäºå‡ ä½•è·ç¦»çš„åº¦é‡æ–¹å¼ï¼Œç”¨æ¥åº¦é‡ä¸¤ä¸ªæ¦‚ç‡çš„å·®å¼‚çš„è·ç¦»ã€‚\n",
    "\n",
    "    - > &emsp;&emsp;ç›¸å¯¹ç†µï¼ˆrelative entropyï¼‰ï¼Œåˆè¢«ç§°ä¸ºKullback-Leibleræ•£åº¦ï¼ˆKullback-Leibler divergenceï¼‰æˆ–ä¿¡æ¯æ•£åº¦ï¼ˆinformation divergenceï¼‰ï¼Œæ˜¯ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼ˆprobability distributionï¼‰é—´å·®å¼‚çš„éå¯¹ç§°æ€§åº¦é‡  ã€‚\n",
    "    - > &emsp;&emsp;åœ¨åœ¨ä¿¡æ¯ç†è®ºä¸­ï¼Œç›¸å¯¹ç†µç­‰ä»·äºä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„ä¿¡æ¯ç†µï¼ˆShannon entropyï¼‰çš„å·®å€¼ã€‚\n",
    "    - >&emsp;&emsp;ç›¸å¯¹ç†µæ˜¯ä¸€äº›ä¼˜åŒ–ç®—æ³•ï¼Œä¾‹å¦‚æœ€å¤§æœŸæœ›ç®—æ³•ï¼ˆExpectation-Maximization algorithm, EMï¼‰çš„æŸå¤±å‡½æ•°  ã€‚æ­¤æ—¶å‚ä¸è®¡ç®—çš„ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒä¸ºçœŸå®åˆ†å¸ƒï¼Œå¦ä¸€ä¸ªä¸ºç†è®ºï¼ˆæ‹Ÿåˆï¼‰åˆ†å¸ƒï¼Œç›¸å¯¹ç†µè¡¨ç¤ºä½¿ç”¨ç†è®ºåˆ†å¸ƒæ‹ŸåˆçœŸå®åˆ†å¸ƒæ—¶äº§ç”Ÿçš„ä¿¡æ¯æŸè€— ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- è®¡ç®—å…¬å¼ï¼š\n",
    "    - ä¿¡æ¯ç†µï¼š$H(x) = - \\sum \\limits _{i=1} ^ N p(x_i) log \\ p(x_i)$\n",
    "    - æ•£åº¦ï¼š$D_{KL}(p | q) = \\sum \\limits _{i=1} ^ N p(x_i) (log \\ p(x_i) - log \\  q(x_i)) = \\sum \\limits _{i=1} ^ N p(x_i) log \\dfrac{p(x_i)}{q(x_i)} $\n",
    "    \n",
    "    - Torchä¸­å°è£…çš„å…¬å¼ï¼š\n",
    "        - $loss(x, target) = target (log (target) - x)$ï¼štarget=0çš„æƒ…å†µæ€»ä½“çœ‹æˆ0ï¼Œåªè€ƒè™‘targetä¸º1çš„æƒ…å†µ\n",
    "        - $loss(x, target) = target (- x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å‡½æ•°å®šä¹‰\n",
    "\n",
    "```python\n",
    "    torch.nn.functional.kl_div(input, target, size_average=None, reduce=None, reduction='mean')\n",
    "    \n",
    "```\n",
    "\n",
    "- å‚æ•°è¯´æ˜ï¼š\n",
    "    - reductionå‚æ•°ï¼šbatchmeanæœ€åçš„å‡å€¼ä½¿ç”¨batch_sizeï¼Œmeanä½¿ç”¨è¾“å‡ºçš„ä¸ªæ•°ï¼›\n",
    "        - æ³¨æ„batch_sizeä¸è¾“å‡ºæ€»æ•°æ˜¯æœ‰å·®åˆ«çš„ã€‚å¦‚æœæ˜¯ï¼ˆNï¼Œ1ï¼‰ç»´åº¦ï¼Œåˆ™æ²¡æœ‰å·®åˆ«ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä¾‹å­ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9451)\n",
      "tensor(-0.9451)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import torch\n",
    "\n",
    "data, target = sklearn.datasets.load_iris(return_X_y=True)\n",
    "\n",
    "x = torch.Tensor(data[:100])   #  ï¼ˆ150ï¼Œ4ï¼‰\n",
    "y = torch.Tensor(target[:100]).view(100, 1) # ï¼ˆ150, 1ï¼‰\n",
    "\n",
    "w = torch.randn(1, 4)    # æ³¨æ„å½¢çŠ¶(linearä¼šè‡ªåŠ¨è½¬ç½®) ï¼š3è¡¨ç¤ºç±»åˆ«æ•°æ®ï¼ˆè¾“å‡ºçš„é•¿åº¦ï¼‰\n",
    "b = torch.randn(1)        # wï¼Œbæ˜¯å¯è®­ç»ƒçš„ï¼Œå°±æ˜¯éœ€è¦æ±‚å¯¼æˆ–è€…æ¢¯åº¦\n",
    "\n",
    "y_ = torch.nn.functional.linear(input=x, weight=w, bias=b)  \n",
    "sy_ = y_\n",
    "loss = torch.nn.functional.kl_div(sy_, y, reduction=\"batchmean\")   \n",
    "print(loss)\n",
    "\n",
    "# æ‰‹å·¥è®¡ç®—ï¼ˆæœ¬è´¨ä¸nll_losså‡½æ•°ä¸€æ ·ï¼šnll_lossæ”¯æŒå¤šç±»ï¼‰\n",
    "loss_manual = - y * (sy_)\n",
    "print(loss_manual.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hinge_embedding_losså‡½æ•°\n",
    "\n",
    "- ç”¨æ¥æµ‹è¯•ä¸¤ä¸ªè¾“å…¥çš„æ•°æ®æ˜¯å¦ç›¸ä¼¼ã€‚\n",
    "    - yçš„å–å€¼ä¸º-1æˆ–è€…1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å‡½æ•°å®šä¹‰\n",
    "\n",
    "```python \n",
    "    torch.nn.functional.hinge_embedding_loss(input, target, margin=1.0, size_average=None, reduce=None, reduction='mean') â†’ Tensor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å‡½æ•°å…¬å¼ï¼š\n",
    "    - $loss(x,y) = \\begin{cases} x& å¦‚ y =1\\\\ max(0, 1 -x )&å¦‚y=-1 \\\\   \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ä¾‹å­ä»£ç ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3959)\n",
      "tensor(0.3959)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import torch\n",
    "\n",
    "data, target = sklearn.datasets.load_iris(return_X_y=True)\n",
    "target[target == 0] = -1 \n",
    "x = torch.Tensor(data[:100])   #  ï¼ˆ150ï¼Œ4ï¼‰\n",
    "y = torch.Tensor(target[:100]).view(100, 1) # ï¼ˆ150, 1ï¼‰\n",
    "w = torch.randn(1, 4)    # æ³¨æ„å½¢çŠ¶(linearä¼šè‡ªåŠ¨è½¬ç½®) ï¼š3è¡¨ç¤ºç±»åˆ«æ•°æ®ï¼ˆè¾“å‡ºçš„é•¿åº¦ï¼‰\n",
    "b = torch.randn(1)        # wï¼Œbæ˜¯å¯è®­ç»ƒçš„ï¼Œå°±æ˜¯éœ€è¦æ±‚å¯¼æˆ–è€…æ¢¯åº¦\n",
    "\n",
    "y_ = torch.nn.functional.linear(input=x, weight=w, bias=b)  \n",
    "sy_ = y_\n",
    "# print(y_)\n",
    "# sy_ = y_.sigmoid()\n",
    "loss = torch.nn.functional.hinge_embedding_loss(sy_, y, reduction=\"mean\")   # é»˜è®¤å‡å€¼ï¼šæ¯”è¾ƒå¸¸é‡‡ç”¨ï¼ˆå¤šä¸€ä¸ªsigmoidè¿ç®—ï¼‰\n",
    "print(loss)\n",
    "\n",
    "# æ‰‹å·¥è®¡ç®—ï¼ˆæœ¬è´¨ä¸nll_losså‡½æ•°ä¸€æ ·ï¼šnll_lossæ”¯æŒå¤šç±»ï¼‰\n",
    "loss_manual[0:50] = 1 - sy_[0:50]\n",
    "loss_manual[loss_manual< 0] = 0\n",
    "\n",
    "loss_manual[50:100] = sy_[50:100]\n",
    "# loss_manual[loss_manual <0] = 0\n",
    "print(loss_manual.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å…¶ä»–æŸå¤±å‡½æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å…¶ä»–æŸå¤±å‡½æ•°æ˜¯åŸºäºå¤šåˆ†ç±»ä¸å…¶ä»–ç›®çš„çš„å˜ç§å‡½æ•°ï¼Œè¿™äº›æŸå¤±å‡½æ•°åœ¨ç‰¹å®šçš„éœ€æ±‚ç†è§£ä¼šæ›´åŠ å®¹æ˜“ã€‚\n",
    "    - æ¯”å¦‚ï¼šsoft_margin_lossæ˜¯åŸºäºSVMçš„è½¯è·ç¦»æå‡ºçš„ä¸€ç§æŸå¤±ä¼˜åŒ–æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
